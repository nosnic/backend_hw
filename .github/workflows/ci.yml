name: CI

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      db:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      rabbitmq:
        image: rabbitmq:3-management
        env:
          RABBITMQ_DEFAULT_USER: guest
          RABBITMQ_DEFAULT_PASS: guest
        ports:
          - 5672:5672
          - 15672:15672
        options: >-
          --health-cmd "rabbitmq-diagnostics -q ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov pytest-mock httpx

      - name: Wait for services
        run: |
          echo "Waiting for PostgreSQL..."
          timeout 60 bash -c 'until pg_isready -h localhost -p 5432; do sleep 1; done'
          echo "PostgreSQL is ready!"
          
          echo "Waiting for RabbitMQ..."
          timeout 60 bash -c 'until curl -s http://localhost:15672 > /dev/null; do sleep 1; done'
          echo "RabbitMQ is ready!"

      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/postgres
          RABBITMQ_URL: amqp://guest:guest@localhost/
        run: |
          python -m pytest app/test_main.py -v \
            --cov=app \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=json \
            --cov-fail-under=90 \
            --asyncio-mode=auto \
            --junitxml=junit.xml \
            2>&1 | tee pytest-output.txt

      - name: Generate Test Summary
        if: always()
        run: |
          echo "## ðŸ§ª Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² pytest
          if [ -f pytest-output.txt ]; then
            PASSED=$(grep -oP '\d+(?= passed)' pytest-output.txt | tail -1 || echo "0")
            FAILED=$(grep -oP '\d+(?= failed)' pytest-output.txt | tail -1 || echo "0")
            SKIPPED=$(grep -oP '\d+(?= skipped)' pytest-output.txt | tail -1 || echo "0")
            WARNINGS=$(grep -oP '\d+(?= warning)' pytest-output.txt | tail -1 || echo "0")
            
            echo "### Test Statistics" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| âŒ Failed | $FAILED |" >> $GITHUB_STEP_SUMMARY
            echo "| â­ï¸ Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            echo "| âš ï¸ Warnings | $WARNINGS |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ð¸Ð· Ð²Ñ‹Ð²Ð¾Ð´Ð° pytest
          if [ -f pytest-output.txt ]; then
            # Ð˜Ñ‰ÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð²Ð¸Ð´Ð° "TOTAL ... 95%"
            COVERAGE=$(grep -oP 'TOTAL\s+\d+\s+\d+\s+\d+\s+\d+\s+\K\d+(?=%)' pytest-output.txt | tail -1 || echo "0")
            
            echo "### ðŸ“Š Code Coverage" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð¸ Ñ†Ð²ÐµÑ‚ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð° Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸Ñ
            if [ "$COVERAGE" -ge 90 ]; then
              BADGE_COLOR="brightgreen"
              EMOJI="ðŸŸ¢"
            elif [ "$COVERAGE" -ge 80 ]; then
              BADGE_COLOR="green"
              EMOJI="ðŸŸ¡"
            elif [ "$COVERAGE" -ge 70 ]; then
              BADGE_COLOR="yellow"
              EMOJI="ðŸŸ "
            else
              BADGE_COLOR="red"
              EMOJI="ðŸ”´"
            fi
            
            echo "#### $EMOJI Total Coverage: **${COVERAGE}%**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "![Coverage](https://img.shields.io/badge/coverage-${COVERAGE}%25-${BADGE_COLOR})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Ð’Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
          if [ -f pytest-output.txt ]; then
            DURATION=$(grep -oP '\d+\.\d+(?=s)' pytest-output.txt | tail -1 || echo "N/A")
            echo "â±ï¸ **Test Duration:** ${DURATION}s" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¦ **Artifacts:**" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage HTML Report (available in workflow artifacts)" >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: always()
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 30

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy

      - name: Run flake8
        continue-on-error: true
        run: |
          flake8 app/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 app/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Check code formatting with black
        continue-on-error: true
        run: |
          black --check app/

      - name: Check import sorting with isort
        continue-on-error: true
        run: |
          isort --check-only app/

  docker-build:
    runs-on: ubuntu-latest
    needs: [test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        run: |
          docker build -t backend-app:test .

      - name: Test Docker image
        run: |
          docker images backend-app:test